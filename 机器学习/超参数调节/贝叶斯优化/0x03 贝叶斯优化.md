## 贝叶斯优化

#### 为何使用贝叶斯优化

$$x$$为一组超参数, $$f(x)$$为评价模型预测结果的指标函数, 往往是值越大越好. 因此, 超参数的选择的目标等同于$$\max\limits_{x\in{\mathcal{X}}}f(x)$$.

但$$f(x)$$没有解析表达式, 其形式位置, 不能使用与梯度相关的优化算法.

而且常用的**Grid Search**和**Random Search**都是效果一般的算法, 在有限计算资源下的调参不一定比手动调节更好.

#### 贝叶斯优化过程

首先明确**贝叶斯优化**算法模型中, 样本点的概念. 这里每个样本点是由**一组超参数**和对应的**模型评价函数值**共同组成.

假设已经存在几个样本点, 通过**高斯过程回归**, 我们认为所有超参数样本点之间符合**联合高斯分布**. 因此, 计算前面$$n$$个点的**后验概率分布**, 得到超参数在每一个取值点的分布, 由于在每个点上都是一个**高斯分布**, 得到分布就得到了这个超参数点的**均值**和**方差**. 下图中虚线就是计算的每个超参数取值点的均值得到的曲线, 绿色范围就是高斯分布与方差有关的置信区间.

![](https://pic3.zhimg.com/80/v2-514968db5ac849537555b590bc49b122_hd.jpg)

均值越大, 表示模型的最终评价指标值越大, 方差表示这个点结果的不确定性, 因此:

- 均值大代表期望越好, 选择均值大的点作为下一个探索点称之为**explortation**, 即**开发**
- 方差大的点也有可能存在**全局最优点**, 即结果的可能上限高, 选择方差大的点作为下一个探索点我们称之为**exploration**探索.

我们选取下一组超参数作为下一个探索点, 就需要权衡**explortation**和**exploration**. 使用**acquisition function**完成这项工作. 对于**acquisition function**有多种选择, 常见的有以下几个, 会在后面详细描述:

- Upper confidence bound
- Expected improvement
- Entropy search

对于每一步, 求得**acquisition function**的最大值, 最大值这个点对应的超参数就是优化过程中算法在当前步推荐的一组超参数值.

![](https://pic2.zhimg.com/80/v2-feaace833ceeab0019d856e0b48960b0_hd.jpg)

比如上图中下方图中的星星就是当前步选择的最优超参数点. 这组超参数是根据超参数间的联合概率分布求出, 并且权衡了**explortation**和**exploration**后得到的结果.

使用这组超参数训练模型, 得到模型的评价指标的数值. 这样对于贝叶斯优化模型来说样本数就增加了一个, **重新计算**超参数之间的**后验概率分布**和**acquisition function**:

![](https://pic1.zhimg.com/80/v2-14e97b380ff8cf92386f997eb68d8fe2_hd.jpg)

不断重复上述步骤.

#### 贝叶斯优化的数学表达

贝叶斯算法的核心步骤为:

- 通过样本点$$D=\{(x_1,y_1),\cdots,(x_t, y_t)\}$$构建联合概率分布, 得到对所有$$x$$点的后验概率分布$$f(x)$$, 也即高斯过程$$f(x)$$
- 通过上面计算得到的高斯过程计算得到**acquisition function** $$a(x)$$, 根据$$a(x)$$的最大值对应的点直到下次采样

我们需要估计的模型就是**高斯过程** $$f(x)$$, 即模型在每组超参数的表现的**分布**如何, 将高斯过程记为:

$$f(x)\sim GP(E(x), K(x,x^{'} ))$$

均值函数是关于超参数$$x$$的函数, **协方差矩阵**是关于超参数的**核函数**.

对于一组样本点$$D=\{(x_1,y_1),\cdots,(x_t, y_t)\}$$, 为了方便推导, 假设数据被中心化即$$f(x)\sim GP(0, K)$$, 其中$$K$$为:

$$\left[ \begin{matrix} k(x_1, x_1) & \cdots & k(x_1, x_t) \\ \vdots & \ddots & \vdots \\ k(x_t, x_1) & \cdots & k(x_t, x_t) \end{matrix} \right]$$

对于一个新样本$$x_{t+1}$$, 则协方差矩阵更新如下:

$$ K= \left[\begin{matrix} K & k^T \\ k & k(x_{t+1}, x_{t+1}) \end{matrix}\right]$$

其中$$k$$向量由核函数计算得到$$k=[k(x_{t+1}, x_1), k(x_{t+1}, x_2), \cdots, k(x_{t+1}, x_t)]$$.

有了新的协方差矩阵, 就可以根据前$$t$$个样本估计出$$f(x_{t+1})$$的**后验概率分布**:

$$P(f_{t+1}|D_{1:t}, x_{t+1}) \sim N(\mu, \sigma^2)$$

$$\mu = k^TK^{-1}f_{1:t}$$

$$\sigma^2 = k(x_{t+1}, x_{t+1}) - k^TK^{-1}k$$

对于每个超参数点, 我们都能计算得到这个**后验概率分布**, 如何根据所有点的分布确定下一组实验的超参数, 就要使用到之前所说的**acquisition function** $$a(x)$$. 其作用在上一小节中有描述, 下面介绍常用的两种方程:

- **Upper Confidence Bound**

  $$a(x|D)=UCB(x)=\mu(x) + \alpha \sigma(x)$$

  其中$$\alpha$$是一个超参数. 这个函数的意义是均值加上一定倍数的标准差作为判别.

- **Expected Improvement**

  首先定义$$f_{best}$$为历史样本点中评价指标的最大值, 是一个经过训练预测得到的确定的数值. 则有:

  $$\begin{align} a(x|D) &= E_{y\sim{f(x|D)}}[\max(0, y-f_{best})] \\ &= \int_0^{\infty} (y-f_{best})P(y>f_{best})d(y-f_{best}) \\ &= \int_0^{\infty} \xi p(f_{best}+\xi)d\xi \\ &= \int_0^{\infty} \xi \frac{1}{\sqrt{2\pi}\sigma(x)}\exp(-\frac{(\mu(x)-f_{best}-\xi)^2}{2\sigma^2(x)})d\xi \\ &= \sigma(x)z\Phi(z) + \sigma(x)\phi(z) \end{align}$$

  其中$$z=\frac{f_{best}-\mu(x)}{\sigma(x)}$$, $$\Phi(\cdot)$$是高斯分布的**累计概率函数**, $$\phi(\cdot)$$是高斯分布的**概率密度函数**. 所以有:

  $$a(x|D)=E_{y\sim{f(x|D)}}[\max(0, y-f_{best})]=\begin{cases} \sigma(x)z\Phi(z) + \sigma(x)\phi(z), \quad & y>f_{best} \\ 0, \quad & \text{otherwise} \end{cases}$$

#### 贝叶斯优化中的超参数

贝叶斯优化模型本身也是有超参数的, 可以称之为*超超参数*, 例如**acquisition function**的选择等. 对于这些*超超参数*, 使用业界公认的比较好的方案即可.

