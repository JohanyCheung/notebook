## 引入

本文是论文**Metadata Embeddings for User and Item Cold-start Recommendations**的阅读笔记.

本片论文是用来进行推荐任务的**LightFM**包对应的原理. 对应的代码地址为[lightfm](https://github.com/lyst/lightfm), 论文地址为[arXiv](https://arxiv.org/abs/1507.08439). 对应包使用的说明文档地址为[Welcome to LightFM’s documentation!](https://lyst.github.io/lightfm/docs/home.html).

通常使用**Matrix factorization**(矩阵向量化)这类模型来做推荐任务, 会将所有的`user`和`item`根据他们之间的相互联系, 计算出分别的向量. 即每个`user`或`item`都会对应一个向量, 这个向量可以是通过主题模型, 矩阵分解, embedding, 或梯度迭代计算得到的.

但这种方法有个无法解决的问题, 即**冷启动**问题. 因为新的`user`或`item`没有相关联的信息, 无法计算得到对应的代表向量.

使用**Content-based**(CB)模型能够解决这个问题. CB模型将`item`通过其对应的**metadata**进行表示, 对于`user`也是相同的操作, 只是两者的metadata的内容不同. 这里的metadata可以看做属性, 对于单个`user`和`item`, 都对应着多个不同的属性. 这些属性是提前知道的, 不需要等到有交互操作时才产生. 然后通过一定的逻辑, 将这些属性综合起来, 得到一个`user`或`item`对应的向量.

但一般的CB模型, 将不同的`user`独立开来, 忽视了`user`之间的联系, 这就导致了CB模型在有关联数据的情况下, 表现比MF模型差很多, 因此对应的冷启动结果也会较差.

## 模型原理

**LightFM**模型是一种混合了上面两种思想的**content-collaborative**模型. 具体来说:

- LightFM是一种MF模型. 这是因为它使用了**协同过滤矩阵**, 与**协同过滤模型**一样, 最终得到`user`和`item`对应的向量的这种思想, 整体上与MF模型是一致的.
- LightFM是一种CB模型, 因为它是基于**content-collaborative**的. `user`和`item`对应的向量不是直接计算得到的, 而是通过对应的**metadata**组合得到的.

具体来说相对于普通的协同过滤模型中的`user`和`item`交互关系, LightFM中的交互关系不是两者直接的, 而是**content-collaborative**, 这里的content指的就是**metadata**. `user`对应一个metadata集合, `item`对应另一个metadata集合, 交互关系就发生在metadata层面.

举例来说, 假设`user`A具有三种属性, `item`B具有三种属性, 所以交互是这两组属性之间发生的, MF也是在这个层面上进行的, 得到的是每个**metadata对应的向量**, 这里指的是`user`以及`item`的metadata.

然后, 对于`user`, 其对应的向量是这个`user`包含的所有`metadata`对应的向量的**加和平均**.

通过这种方法, 综合了**content-based**和**collaborative recommender**两种角度, 也解决了冷启动的问题.

---

LightFM模型也可以完全等价于普通的MF模型. 如果每个`user`都只对应一个`metadata`, 而且不同的`user`对应的`metadata`没有重复, 就可以理解为`user`的metadata中包含的就是每个user的指示属性, 等价于one-hot. 因此就没有后面的metadata组合的步骤, 得到的向量直接就是`user`或`item`对应的向量.

## 模型定义

使用数学符号正式地定义模型.

$$U$$为`user`集合, $$I$$为`item`集合. $$F^U$$为`user`的特征集合, 即`user`的metadata集合, 一个`user`可以有多个metadata(特征). $$F^I$$是`item`的特征集合.

每个`user`都可能与多个`items`发成交互关系, 这种关系可能是正面的, 也可能是负面的(对于评分评级系统来说, 关系是比较复杂的, 行为关系就只是二值关系). 所有`user-item`交互对记为$$(u,i)\in{U\times{I}}$$. 这个集合是正面交互集合$$S^{+}$$和负面交互集合$$S^{-}$$的并集.

`user`和`item`在这里都是假定完全可以被他们的metadata所描述的. 对于每个`user`$$u$$, 它所包含的所有的metadata集合记为$$f_u\in{F^U}$$, 同理, 对于每个`item`$$i$$, 它所包含的所有的metadata集合记为$$f_i\in{F^I}$$.

对于`user`和`item`对应的每个metadata(特征)$$f$$, 分别用等长的($$d$$维的)embedding向量$$e_f^U$$和$$e_f^I$$来表示. 对应的每个metadata(特征)还有一个偏置$$b_f^U$$, $$b_f^I$$.

因此, `user`$$u$$对应的向量为其包含的所有metadata对应embedding向量的和:

$$\mathbb{q}_u=\sum\limits_{j\in{f_u}}\mathbb{e}_j^U$$

`item`$$i$$对应的向量为:

$$\mathbb{p}_i=\sum\limits_{j\in{f_i}}\mathbb{e}_j^I$$

`user`$$u$$对应的偏置也是对应之和:

$$b_u=\sum\limits_{j\in{f_u}}b_j^U$$

`item`$$i$$对应的偏置为:

$$b_i=\sum\limits_{j\in{f_j}}b_i^I$$

模型对`user`$$u$$和`item`$$i$$的预测值为两个embedding向量的点积再加上对应的偏置:

$$\hat{r}_{ui}=f(q_u \cdot p_i + b_u + b_i)$$

这里的函数$$f(\cdot)$$在**评分系统**同一般使用**identity function**即$$f(x)=x$$, 在二值数据中使用**sigmoid**函数.

在最优化求解步骤中, 极大似然函数:

$$L(e^U, e^I, b^U, b^I)=\prod\limits_{(u,i)\in{S^{+}}}\hat{r}_{ui} \times \prod\limits_{(u,i)\in{S^{-}}}(1-\hat{r}_{ui})$$

## 使用

LightFM中提供了4种损失函数, 上面的损失函数只是默认指定的`logistic`损失函数. 另外还有`BPR`, `WARP`, `k-OS WARP`等损失函数. 再配合`adagrad`或`adadelta`两种learning rate调整策略进行训练.
