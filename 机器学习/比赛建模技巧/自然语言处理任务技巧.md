### TF-IDF + Ngram

句子/文章的**TF-IDF**特征向量, 在快速构建baseline有则关键的作用, 甚至可以作为最终模型的一个stacking成分.

在构建TF-IDF的时候, 可以结合**Ngram**. 如果使用单词进行构建, 相当于使用的是**1gram**. 可以将单词结合起来, 用**词对**的形式表示, **2gram**, **3gram**(没有必要使用更高的值, 因为除了计算慢之外, 带来的提升也是有限的), 将独立的词对也作为新的特征, 与单词(1gram)并列, 这样特征维度就被大大增加了, 而且也带有了上下文的信息, 部分弥补了词袋模型的缺点.

### CountVector特征

除了TF-IDF, **词袋模型**还有一种重要的表征方法, 就是**词频统计**, 特征的维度与TF-IDF相同, 就是词典的长度. 对于每个样本(句子/文章), 统计每个单词的词频使用.

往往可以取得和TF-IDF相差不多的成绩. 然后作为两个不同角度的模型, 进行融合提升最终的结果.

### Word level与Char level

比赛中往往同一个模型, 我们可以从word和char两个不同的层级出发, 训练模型, 分别使用word和char两套不同的embedding向量, 输入的形式相同, 内容和序列长度不同, 训练同样的模型, 然后平均或stacking使用.

当然, 也可以融入其他的level, 例如使用**subword**方法对word进行拆分, 得到介于char和word之间级别的表示, 使用同样的方法训练, 然后融合.
