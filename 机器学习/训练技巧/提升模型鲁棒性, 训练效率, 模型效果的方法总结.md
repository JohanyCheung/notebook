## 预处理方法

- 数据增强(data augmentation), 对于文字和图像等不同类型的数据有不同的增强方式

## 模型结构

- **batch normalization**
- **Dropout**
  - 可以理解成训练了无数个共享同一套参数的不同结构的模型(结点被随机抛弃), 在预测时将所有的模型**隐式地**集成起来, 得到最终的结果
- **DropConnect**, 类似于Dropout, 随机断开的是连接而不是结点.
- **Stochastic Depth technique**, 与上面的也类似, 随机抛弃某些层, 在预测时也是**隐式地**集成了多种结构的模型.
- **Swapout**, 同时使用Dropout和Stochastic Depth.

## 训练技巧

- **Adam**降低到一定水平后, 切换成**SGD**
- SGD收敛后使用一个较大的**learning rate**跳出当前的局部极小, 再改用小的**learning rate**寻找附近的新的局部极小
- NLP问题中, **word embedding**使用预训练好的参数, 在模型刚开始时关闭训练, 减少干扰, 在模型收敛到一定程度后, 打开训练, 使之适合当前应用.

## 模型集成

- 同模型多次训练, 将预测结果进行集成, 比如通过投票或者求均值
- **Snapshot Ensemble**, 高效完成集成.
