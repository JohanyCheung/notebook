## 排序问题

排序问题的解决方法就是著名的**LTR**(Learning To Rank)相关的算法.

## 问题场景

对于搜索场景, 如根据搜索词返回网页链接, 或文章推荐, 商品推荐等等. 最原始的解决方法是使用特定的公式计算**Query**和**Document**之间的相似程度, 然后根据相似度进行排序, 相似度高的排列在前面. 这种方法只能应用与非常粗糙的场景中.

使用机器学习模型, 对**Quert-Document**对进行特征工程, 创建很多的特征, 然后使用机器学习的模型在训练数据即上进行训练, 然后对新的**Quert-Document**对进行预测.

机器学习模型多为**分类**或**回归**模型, 不能直接的被应用于排序. 因此想要解决排序问题, 就需要对排序问题进行一些改造.

## 训练数据生成

首先了解LTR相关算法的训练数据是什么形式的, 如何将实际场景中的数据改造成可用于LTR算法的数据.

首先可用于训练的**标签**数据主要来自于两种方法:

- 人工标注
- 搜索日志

### 人工标注

从搜索的日志中, 随机地**选取一部分Query**, 然后让专业的数据评估员, 对这次Query产生的**Quert-Document对**(对于网页搜索则是)给出**相关性判断**, 根据模型的种类(二分类, 多分类, 回归), 给出结果, 常见的是5档的评分: `差, 一般, 好, 优秀, 完美`, 以此作为训练数据.

人工标注是标注者的主观判断, 会受标注者背景知识等因素的影响, 往往需要多人同时进行标注, 最后以类似投票表决的方式决定这个Quert-Document对的相关程度, 可以相对减少各个人的观点不同带来的误差.

### 搜索日志

搜索日志记录了人们在实际生活中的搜索行为和相应的点击行为, 点击行为实际上隐含了Quert-Document对的**相关性**, 所以可以被用来作为Quert-Document对的相关程度的判断.

一种最简单的方法就是利用同一个query下, 同doc的点击数的多少来作为它们相关程度的大小. 但这个方法有一个很大的问题, 被称为**点击偏见**(Click Bias)或**position bias**, 即用户偏向于点击位置靠前的doc, 即便这个doc并不相关或者相关性不高, 最后导致高位置的结果被点击的概率会大于低位置的结果.

为了去除或缓解这个问题, 可以通过以下的方法获取标签:

- 当位置靠后的doc的点击数都比位置靠前的doc的点击数要高了, 那么靠后的doc的相关性肯定要比靠前的doc的相关性大
- 一个比较tricky的方法, 如果两个doc的差距大到一定程度, 即使前者比后者位置靠前, 这时候我们还是愿意相信前者更加相关. 这个差距的大小需要根据每个场景具体的调整, 即引入了一个**超参数**
- 在实际应用中, 除了点击数据, 往往还会使用更多的数据, 比如**页面停留时间**等维度

使用搜索日志以及一定的规则生成的样本标签存在一个问题, 即只有**被搜索次数较多的Query**(Top Query)才能产生足够数量能说明问题的搜索日志, 且有用户点击的query毕竟只是总体query的一个子集, 无法获取全部的query下doc的label, 在**长尾**query中更是如此.

## 特征生成

此阶段就是要抽取出所有的特征, 供后续训练使用. 一般LTR模型的特征分为两大类:

- **relevance**: 即query-doc对的相关性特征, 如文本相关性, Query term在文档中出现的次数等
- **importance/hotness**: doc本身的(热门程度)特征, 如**Pagerank**, **BM25**, 内容丰富度, 是否是spam等

整体一套特征例如:

- 查询词在文档中的词频信息
- 查询词的IDF信息
- 文档长度
- 网页的入链数量
- 网页的出链数量
- 网页的pageRank值 
- 査询词的Proximity值, 即在文档中多大的窗口内可以出现所有査询词

经过上面两个步骤, 就得到了样本的 **(x, y)** 的形式, 即**特征向量**及其对应的**相关性得分(分类)**, 这样就形成了一个具体的训练样本.

## 数据集

- [LETOR: Learning to Rank for Information Retrieval](https://www.microsoft.com/en-us/research/project/letor-learning-rank-information-retrieval/?from=http%3A%2F%2Fresearch.microsoft.com%2Fen-us%2Fum%2Fbeijing%2Fprojects%2Fletor%2F)
- [Microsoft Learning to Rank Datasets](https://www.microsoft.com/en-us/research/project/mslr/?from=http%3A%2F%2Fresearch.microsoft.com%2Fen-us%2Fprojects%2Fmslr%2F)
- [Yahoo Learning to Rank Challenge](https://webscope.sandbox.yahoo.com/catalog.php?datatype=c)

## 参考资料

- [Learning to Rank简介](http://www.cnblogs.com/bentuwuying/p/6681943.html)
- [Learning to Rank入门小结 + 漫谈](http://www.cnblogs.com/wentingtu/archive/2012/03/13/2393993.html)
