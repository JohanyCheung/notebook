## 分类数据分析

对**分类数据**进行分析的统计方法, 主要是利用$$\chi^2$$**分布**, 因此, 对分类数据的假设检验, 又称为**$$\chi^2$$检验**, $$\chi^2$$检验的应用主要表现在两方面:

- **拟合优度检验**
- **独立性检验**

**列联表**是进行**独立性检验**的重要工具.

## 分类数据与$$\chi^2$$统计量

$$\chi^2$$可以用于测定两个分类变量之间的**相关程度**. 如果用$$f_o$$表示观测值的**频数**(注意是频数, 因此只能使用在类别特征上), 用$$f_e$$表示期望值频数, 则$$\chi^2$$统计量可以写为:

$$\chi^2=\sum \frac{(f_o-f_e)^2}{f_e}$$

而$$\chi^2$$统计量有以下的特征:

- $$\chi^2$$统计量的分布与自由度有关, 自由度越小, 分布就越向左倾斜, 当自由度比较大时, $$\chi^2$$分布就趋近于对称的正态分布了.
- $$\chi^2$$统计量描述了**观测值**与**期望值**之间接近的程度, 两者越接近, $$f_o-f_e$$的绝对值越小, 得到的$$\chi^2$$值也就越小.

$$\chi^2$$检验正是通过$$\chi^2$$的计算结果, 与$$\chi^2$$分布中的临界值进行比较, 做出是否拒绝原假设的统计决策.

## 拟合优度检验

**拟合优度检验**(goodness of fit test)是用$$\chi^2$$统计量进行统计**显著性检验**的重要内容. 依据总体分布的情况, 计算出分类变量中类别的期望频数, 与分布的观测频数进行对比, 判断期望频数与观测频数之间是否有显著的差异, 从而达到对分类变量进行分析的目的.

对应于实际, 需要解决一个分类问题, 因此每个样本对应一个类别; 检验的是一个**类别特征**, 是离散的, 特征的值没有数值意义的, 只需要通过对这个特征分类计数(value count)即可.

对于这类检验, 我们的原假设$$H_0$$为观测频数与期望频数一致. 首先计算$$\chi^2$$统计量. 此统计量服从自由度为$$df$$的$$\chi^2$$分布, $$df=R-1$$, $$R$$为**分类变量**中类型的个数(`len(unique(x))`).

如果计算得到的$$\chi^2$$统计量大于$$\chi^2_{\alpha}$$, 则拒绝原假设, 认为该分类变量特征与最终的分类结果**显著相关**.

---

对于**总体比例的检验**, 也可以采用拟合优度的方法. 在假设检验的*单个总计的假设检验中*, 使用了$$z$$统计量, 对总体比例$$\pi$$进行了检验.

将其转换成上面的方法, 认为原假设正确, 使用假设的比例计算得到期望频数, 与观测频数一起计算$$\chi^2$$统计量, 然后进行检验的比较, 得出结论.

## 独立性检验

拟合优度检验是对一个分类变量进行检验, 如果想对两个分类变量进行检验, 判断这两个分类变量是否存在联系, 这种分析称为**独立性检验**, 一般通过**列联表**进行分析, 因此也称为**列联分析**.

列联表是由两个以上的变量进行交叉分类的频数分布表. 独立性检验就是分析列联表中行变量和列变量是否相互独立.

列联表中任何一个单元中的频数期望值如下计算:

$$f_e=\frac{RT}{n}\frac{CT}{n}n=\frac{RT \times CT}{n}$$

其中, $$RT$$为给定单元格所在行的总样本数量, $$CT$$为给定单元格所在列的总样本数量, $$n$$为观测值的总个数, 即样本量.

对应的$$\chi^2$$分布的自由度为$$(R-1)(C-1)$$, $$\chi^2$$统计量的计算方法仍然同上, 只不过需要对列联表中的每一个单元格都需要进行计算, 然后加和(拟合优度检验中只有一列).

自由度就是**可以自由取值的数据的个数**, 关于此处自由度为$$(R-1)(C-1)$$的原因, 在`贾俊平`版<统计学>一书的`P223`中有详细的阐述.

## 列联表中的相关测量

如果两个分类变量之间存在联系, 它们之间相关程度有多大, 要如何衡量.

对于两个分类变量之间相关程度的测定, 主要用相关系数表示.

#### $$\varphi$$相关系数

$$\varphi$$相关系数是描述$$2 \times 2$$列联表数据最常用到的一种相关系数, 即要求两个分类变量, 每个变量都有且只有两类. 计算公式为:

$$\varphi=\sqrt{\chi^2/n}$$

$$\chi^2$$就是上面的方法计算得到的$$\chi^2$$值, $$n$$为观测样本的总数量.

$$\varphi$$系数的取值范围在0到1之间, $$\varphi$$的绝对值越大, 说明两个变量之间的相关程度越高. 如果为0说明两个变量之间是完全独立的.

#### 列联相关系数

又称为列联系数, 简称$$c$$系数, 用于列联表**大于**$$2 \times 2$$的情况, 这是因为$$\varphi$$系数随着$$R$$和$$C$$的变大而增大, 没有上限, 因此就没有一个标准来衡量计算得到的值是什么水平, 继而无法产生判断. 因此改进为列联系数, $$c$$系数计算公式为:

$$c=\sqrt{\frac{\chi^2}{\chi^2+n}}$$

两个变量相互独立时, 系数$$c=0$$, 且它的值不会大于1, 其可能的最大值随列联表的行数和列数的增大而增大, 但不会超过1.

#### $$V$$相关系数

$$V$$相关系数的计算公式为:

$$V=\sqrt{\frac{\chi^2}{n \times \min [(R-1), (C-1)]}}$$

当两个变量相互独立时, $$V=0$$, 当两个变量完全相关时, $$V=1$$. 所以$$V$$的取值在0到1之间.

## $$\chi^2$$分布的期望值准则

使用$$\chi^2$$分布进行**独立性检验**要求样本量必须足够大, 特别是每个单元中的期望频数不能过小, 否则使用$$\chi^2$$检验可能会得出错误的结论. 具体来说有以下的要求:

- 如果只有两个单元, 每个单元的期望频数必须大于等于5
- 如果有两个以上的单元, 如果有20%单元的期望频数小于5, 则不能使用该检验方法

这是因为如果期望频数$$f_e$$过小, 计算卡方的公式$$\chi^2=\sum \frac{(f_o-f_e)^2}{f_e}$$将会不适当地增大, 造成$$\chi^2$$统计量的高估, 从而导致不适当地拒绝$$H_0$$的结论. 可以通过合并较小的$$f_e$$, 即合并出现次数不多的类别, 得到合理的结论.

